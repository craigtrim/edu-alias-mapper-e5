{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6129836a-ab0c-4122-992b-3ebb61a9839c",
   "metadata": {},
   "source": [
    "### ğŸ§­ Overview\n",
    "\n",
    "This notebook demonstrates how to use the edu-alias-mapper-e5 model â€” a fine-tuned Sentence Transformer that maps university aliases (e.g., â€œUdeGâ€, â€œmontana.eduâ€) to their canonical names (e.g., â€œUniversity of Guadalajaraâ€, â€œMontana State Universityâ€).\n",
    "\n",
    "To speed up loading in environments like Jupyter, download the model locally once before running:\n",
    "\n",
    "```shell\n",
    "huggingface-cli download craigtrim/edu-alias-mapper-e5 \\\n",
    "  --local-dir ~/.cache/huggingface/hub/models--craigtrim--edu-alias-mapper-e5\n",
    "```\n",
    "\n",
    "After this one-time setup, the notebook loads the model from your local cache for fast, offline lookups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8babc01-c769-43c6-87f7-fb712a5c2131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Temp directory in use â†’ /var/folders/53/k1mcwcc57qzd7rbr7nxb2w7m0000gn/T\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# ğŸ§  Example aliasâ†’label lookup using craigtrim/edu-alias-mapper-e5 (no FAISS needed)\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# ğŸŒ Environment setup\n",
    "# ---------------------------------------------------------------------\n",
    "os.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\"  # hide HF CLI progress bars\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# âš™ï¸ Config: model + data\n",
    "# ---------------------------------------------------------------------\n",
    "MODEL_ID = \"craigtrim/edu-alias-mapper-e5\"\n",
    "BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "DATA_PATH = os.path.join(BASE_DIR, \"data\", \"raw\", \"dbpedia_schools.parquet\")\n",
    "\n",
    "print(f\"ğŸ“ Using dataset at â†’ {DATA_PATH}\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# ğŸ“ Cache paths (portable temp directory)\n",
    "# ---------------------------------------------------------------------\n",
    "TMP_DIR = tempfile.gettempdir()\n",
    "EMB_PATH = os.path.join(TMP_DIR, \"edu_alias_label_embs.npy\")\n",
    "LABELS_PATH = os.path.join(TMP_DIR, \"edu_alias_labels.json\")\n",
    "\n",
    "print(f\"ğŸ“¦ Using cache directory â†’ {TMP_DIR}\")\n",
    "print(f\"ğŸ’¾ Embeddings cache â†’ {os.path.basename(EMB_PATH)}\")\n",
    "print(f\"ğŸ’¾ Labels cache â†’ {os.path.basename(LABELS_PATH)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b434952-bdad-4373-b7e7-250e9fd815ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Loading model â†’ craigtrim/edu-alias-mapper-e5\n",
      "â±ï¸  Model load completed in 1.95s (0.03 min)\n",
      "âœ… Model ready for inference\n",
      "\n",
      "â±ï¸  Data load completed in 0.03s (0.00 min)\n",
      "ğŸ“˜ Loaded 20,202 aliases and 20,272 labels\n",
      "\n",
      "ğŸ§© Encoding 20,272 labels (batch_size=32)â€¦\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b30c8017661f4d1ebdd990847fdafbaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/634 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%\n",
    "# ğŸ•’ Stopwatch helper\n",
    "def timer(label: str = \"\"):\n",
    "    start = time.perf_counter()\n",
    "    def stop():\n",
    "        elapsed = time.perf_counter() - start\n",
    "        print(f\"â±ï¸  {label} completed in {elapsed:,.2f}s ({elapsed/60:.2f} min)\")\n",
    "    return stop\n",
    "\n",
    "\n",
    "# %%\n",
    "# ğŸš€ Load model\n",
    "t = timer(\"Model load\")\n",
    "print(f\"ğŸš€ Loading model â†’ {MODEL_ID}\")\n",
    "model = SentenceTransformer(MODEL_ID)\n",
    "t()\n",
    "print(\"âœ… Model ready for inference\\n\")\n",
    "\n",
    "\n",
    "# %%\n",
    "# ğŸ“š Load data\n",
    "t = timer(\"Data load\")\n",
    "df = pd.read_parquet(DATA_PATH)\n",
    "aliases = df[\"alias\"].dropna().unique().tolist()\n",
    "labels  = df[\"label\"].dropna().unique().tolist()\n",
    "t()\n",
    "print(f\"ğŸ“˜ Loaded {len(aliases):,} aliases and {len(labels):,} labels\\n\")\n",
    "\n",
    "\n",
    "# %%\n",
    "# ğŸ§® Generate label embeddings\n",
    "t = timer(\"Embedding generation\")\n",
    "print(f\"ğŸ§© Encoding {len(labels):,} labels (batch_size=32)â€¦\")\n",
    "\n",
    "label_embs = model.encode(\n",
    "    labels,                 # for testing: use labels[:10]\n",
    "    normalize_embeddings=True,\n",
    "    show_progress_bar=True,\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "t()\n",
    "print(\"âœ… Embeddings generated successfully\\n\")\n",
    "\n",
    "\n",
    "# %%\n",
    "# ğŸ’¾ Persist or load embeddings (cross-platform temp-safe)\n",
    "TMP_DIR = tempfile.gettempdir()\n",
    "EMB_PATH = os.path.join(TMP_DIR, \"edu_alias_label_embs.npy\")\n",
    "LABELS_PATH = os.path.join(TMP_DIR, \"edu_alias_labels.json\")\n",
    "\n",
    "if not os.path.exists(EMB_PATH):\n",
    "    print(f\"ğŸ’¾ Saving embeddings â†’ {EMB_PATH}\")\n",
    "    np.save(EMB_PATH, label_embs)\n",
    "\n",
    "    print(f\"ğŸ’¾ Saving label list â†’ {LABELS_PATH}\")\n",
    "    with open(LABELS_PATH, \"w\") as f:\n",
    "        json.dump(labels, f)\n",
    "else:\n",
    "    print(f\"ğŸ“¦ Loading cached embeddings from {EMB_PATH}\")\n",
    "    label_embs = np.load(EMB_PATH)\n",
    "\n",
    "    print(f\"ğŸ“¦ Loading cached labels from {LABELS_PATH}\")\n",
    "    with open(LABELS_PATH) as f:\n",
    "        labels = json.load(f)\n",
    "\n",
    "print(f\"âœ… Embeddings ready for lookup ({len(labels):,} labels)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ad15fbd-ba17-46e4-ad9a-d6972239b99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Query â†’ University Georgia Athens\n",
      "â±ï¸  Lookup completed in 0.70 seconds (0.01 min)\n",
      "ğŸ“ˆ Top 5 matches:\n",
      "   1. University of Georgia                                        (0.8899)\n",
      "   2. The University of Georgia                                    (0.8422)\n",
      "   3. University of Athens                                         (0.7754)\n",
      "   4. David Aghmashenebeli University of Georgia                   (0.7618)\n",
      "   5. Agricultural University of Georgia                           (0.7483)\n",
      "ğŸ Lookup complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# ğŸ” Lookup helper\n",
    "def lookup(query: str, top_k: int = 5):\n",
    "    \"\"\"Find the most semantically similar university names for a given query.\"\"\"\n",
    "    print(f\"\\nğŸ” Query â†’ {query}\")\n",
    "    t = timer(\"Lookup\")\n",
    "\n",
    "    q_emb = model.encode([query], normalize_embeddings=True)\n",
    "    scores = util.cos_sim(q_emb, label_embs)[0]\n",
    "    top = sorted(zip(labels, scores), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "\n",
    "    t()\n",
    "    print(f\"ğŸ“ˆ Top {top_k} matches:\")\n",
    "    for rank, (lbl, score) in enumerate(top, 1):\n",
    "        print(f\"  {rank:>2}. {lbl:<60} ({float(score):.4f})\")\n",
    "    print(\"ğŸ Lookup complete.\\n\")\n",
    "\n",
    "\n",
    "# %%\n",
    "# ğŸ§ª Example query\n",
    "lookup(\"University Georgia Athens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494c00de-5ca1-4de7-aed3-a6e2fb7d1a81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transcriptiq",
   "language": "python",
   "name": "transcriptiq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
