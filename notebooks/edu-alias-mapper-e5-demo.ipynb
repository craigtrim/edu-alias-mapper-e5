{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6129836a-ab0c-4122-992b-3ebb61a9839c",
   "metadata": {},
   "source": [
    "### 🧭 Overview\n",
    "\n",
    "This notebook demonstrates how to use the edu-alias-mapper-e5 model — a fine-tuned Sentence Transformer that maps university aliases (e.g., “UdeG”, “montana.edu”) to their canonical names (e.g., “University of Guadalajara”, “Montana State University”).\n",
    "\n",
    "To speed up loading in environments like Jupyter, download the model locally once before running:\n",
    "\n",
    "```shell\n",
    "huggingface-cli download craigtrim/edu-alias-mapper-e5 \\\n",
    "  --local-dir ~/.cache/huggingface/hub/models--craigtrim--edu-alias-mapper-e5\n",
    "```\n",
    "\n",
    "After this one-time setup, the notebook loads the model from your local cache for fast, offline lookups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8babc01-c769-43c6-87f7-fb712a5c2131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Temp directory in use → /var/folders/53/k1mcwcc57qzd7rbr7nxb2w7m0000gn/T\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# 🧠 Example alias→label lookup using craigtrim/edu-alias-mapper-e5 (no FAISS needed)\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 🌐 Environment setup\n",
    "# ---------------------------------------------------------------------\n",
    "os.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\"  # hide HF CLI progress bars\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# ⚙️ Config: model + data\n",
    "# ---------------------------------------------------------------------\n",
    "MODEL_ID = \"craigtrim/edu-alias-mapper-e5\"\n",
    "BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "DATA_PATH = os.path.join(BASE_DIR, \"data\", \"raw\", \"dbpedia_schools.parquet\")\n",
    "\n",
    "print(f\"📁 Using dataset at → {DATA_PATH}\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 📁 Cache paths (portable temp directory)\n",
    "# ---------------------------------------------------------------------\n",
    "TMP_DIR = tempfile.gettempdir()\n",
    "EMB_PATH = os.path.join(TMP_DIR, \"edu_alias_label_embs.npy\")\n",
    "LABELS_PATH = os.path.join(TMP_DIR, \"edu_alias_labels.json\")\n",
    "\n",
    "print(f\"📦 Using cache directory → {TMP_DIR}\")\n",
    "print(f\"💾 Embeddings cache → {os.path.basename(EMB_PATH)}\")\n",
    "print(f\"💾 Labels cache → {os.path.basename(LABELS_PATH)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b434952-bdad-4373-b7e7-250e9fd815ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Loading model → craigtrim/edu-alias-mapper-e5\n",
      "⏱️  Model load completed in 1.95s (0.03 min)\n",
      "✅ Model ready for inference\n",
      "\n",
      "⏱️  Data load completed in 0.03s (0.00 min)\n",
      "📘 Loaded 20,202 aliases and 20,272 labels\n",
      "\n",
      "🧩 Encoding 20,272 labels (batch_size=32)…\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b30c8017661f4d1ebdd990847fdafbaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/634 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%\n",
    "# 🕒 Stopwatch helper\n",
    "def timer(label: str = \"\"):\n",
    "    start = time.perf_counter()\n",
    "    def stop():\n",
    "        elapsed = time.perf_counter() - start\n",
    "        print(f\"⏱️  {label} completed in {elapsed:,.2f}s ({elapsed/60:.2f} min)\")\n",
    "    return stop\n",
    "\n",
    "\n",
    "# %%\n",
    "# 🚀 Load model\n",
    "t = timer(\"Model load\")\n",
    "print(f\"🚀 Loading model → {MODEL_ID}\")\n",
    "model = SentenceTransformer(MODEL_ID)\n",
    "t()\n",
    "print(\"✅ Model ready for inference\\n\")\n",
    "\n",
    "\n",
    "# %%\n",
    "# 📚 Load data\n",
    "t = timer(\"Data load\")\n",
    "df = pd.read_parquet(DATA_PATH)\n",
    "aliases = df[\"alias\"].dropna().unique().tolist()\n",
    "labels  = df[\"label\"].dropna().unique().tolist()\n",
    "t()\n",
    "print(f\"📘 Loaded {len(aliases):,} aliases and {len(labels):,} labels\\n\")\n",
    "\n",
    "\n",
    "# %%\n",
    "# 🧮 Generate label embeddings\n",
    "t = timer(\"Embedding generation\")\n",
    "print(f\"🧩 Encoding {len(labels):,} labels (batch_size=32)…\")\n",
    "\n",
    "label_embs = model.encode(\n",
    "    labels,                 # for testing: use labels[:10]\n",
    "    normalize_embeddings=True,\n",
    "    show_progress_bar=True,\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "t()\n",
    "print(\"✅ Embeddings generated successfully\\n\")\n",
    "\n",
    "\n",
    "# %%\n",
    "# 💾 Persist or load embeddings (cross-platform temp-safe)\n",
    "TMP_DIR = tempfile.gettempdir()\n",
    "EMB_PATH = os.path.join(TMP_DIR, \"edu_alias_label_embs.npy\")\n",
    "LABELS_PATH = os.path.join(TMP_DIR, \"edu_alias_labels.json\")\n",
    "\n",
    "if not os.path.exists(EMB_PATH):\n",
    "    print(f\"💾 Saving embeddings → {EMB_PATH}\")\n",
    "    np.save(EMB_PATH, label_embs)\n",
    "\n",
    "    print(f\"💾 Saving label list → {LABELS_PATH}\")\n",
    "    with open(LABELS_PATH, \"w\") as f:\n",
    "        json.dump(labels, f)\n",
    "else:\n",
    "    print(f\"📦 Loading cached embeddings from {EMB_PATH}\")\n",
    "    label_embs = np.load(EMB_PATH)\n",
    "\n",
    "    print(f\"📦 Loading cached labels from {LABELS_PATH}\")\n",
    "    with open(LABELS_PATH) as f:\n",
    "        labels = json.load(f)\n",
    "\n",
    "print(f\"✅ Embeddings ready for lookup ({len(labels):,} labels)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ad15fbd-ba17-46e4-ad9a-d6972239b99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔎 Query → University Georgia Athens\n",
      "⏱️  Lookup completed in 0.70 seconds (0.01 min)\n",
      "📈 Top 5 matches:\n",
      "   1. University of Georgia                                        (0.8899)\n",
      "   2. The University of Georgia                                    (0.8422)\n",
      "   3. University of Athens                                         (0.7754)\n",
      "   4. David Aghmashenebeli University of Georgia                   (0.7618)\n",
      "   5. Agricultural University of Georgia                           (0.7483)\n",
      "🏁 Lookup complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# 🔍 Lookup helper\n",
    "def lookup(query: str, top_k: int = 5):\n",
    "    \"\"\"Find the most semantically similar university names for a given query.\"\"\"\n",
    "    print(f\"\\n🔎 Query → {query}\")\n",
    "    t = timer(\"Lookup\")\n",
    "\n",
    "    q_emb = model.encode([query], normalize_embeddings=True)\n",
    "    scores = util.cos_sim(q_emb, label_embs)[0]\n",
    "    top = sorted(zip(labels, scores), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "\n",
    "    t()\n",
    "    print(f\"📈 Top {top_k} matches:\")\n",
    "    for rank, (lbl, score) in enumerate(top, 1):\n",
    "        print(f\"  {rank:>2}. {lbl:<60} ({float(score):.4f})\")\n",
    "    print(\"🏁 Lookup complete.\\n\")\n",
    "\n",
    "\n",
    "# %%\n",
    "# 🧪 Example query\n",
    "lookup(\"University Georgia Athens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494c00de-5ca1-4de7-aed3-a6e2fb7d1a81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transcriptiq",
   "language": "python",
   "name": "transcriptiq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
